{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1eb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil file csv dari folder\n",
    "#ntar ganti lagi aja pathnya\n",
    "import pandas as pd\n",
    "datatest = pd.read_csv(\"test.csv\")\n",
    "datatrain = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b89f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a2fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd09184",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install markupsafe==2.0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eafb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6acab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>...</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1043</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>226</td>\n",
       "      <td>1412</td>\n",
       "      <td>3476</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>746</td>\n",
       "      <td>857</td>\n",
       "      <td>3895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1270</td>\n",
       "      <td>1366</td>\n",
       "      <td>2396</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>295</td>\n",
       "      <td>1752</td>\n",
       "      <td>3893</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>749</td>\n",
       "      <td>810</td>\n",
       "      <td>1773</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>1700</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>644</td>\n",
       "      <td>913</td>\n",
       "      <td>2121</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1152</td>\n",
       "      <td>1632</td>\n",
       "      <td>1933</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>477</td>\n",
       "      <td>825</td>\n",
       "      <td>1223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>1533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>832</td>\n",
       "      <td>2509</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>457</td>\n",
       "      <td>608</td>\n",
       "      <td>2828</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0       1           1043     1          1.8         1  14       0           5   \n",
       "1       2            841     1          0.5         1   4       1          61   \n",
       "2       3           1807     1          2.8         0   1       0          27   \n",
       "3       4           1546     0          0.5         1  18       1          25   \n",
       "4       5           1434     0          1.4         0  11       1          49   \n",
       "..    ...            ...   ...          ...       ...  ..     ...         ...   \n",
       "995   996           1700     1          1.9         0   0       1          54   \n",
       "996   997            609     0          1.8         1   0       0          13   \n",
       "997   998           1185     0          1.4         0   1       1           8   \n",
       "998   999           1533     1          0.5         1   0       0          50   \n",
       "999  1000           1270     1          0.5         0   4       1          35   \n",
       "\n",
       "     m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0      0.1        193  ...  16        226      1412  3476    12     7   \n",
       "1      0.8        191  ...  12        746       857  3895     6     0   \n",
       "2      0.9        186  ...   4       1270      1366  2396    17    10   \n",
       "3      0.5         96  ...  20        295      1752  3893    10     0   \n",
       "4      0.5        108  ...  18        749       810  1773    15     8   \n",
       "..     ...        ...  ...  ..        ...       ...   ...   ...   ...   \n",
       "995    0.5        170  ...  17        644       913  2121    14     8   \n",
       "996    0.9        186  ...   2       1152      1632  1933     8     1   \n",
       "997    0.5         80  ...  12        477       825  1223     5     0   \n",
       "998    0.4        171  ...  12         38       832  2509    15    11   \n",
       "999    0.1        140  ...  19        457       608  2828     9     2   \n",
       "\n",
       "     talk_time  three_g  touch_screen  wifi  \n",
       "0            2        0             1     0  \n",
       "1            7        1             0     0  \n",
       "2           10        0             1     1  \n",
       "3            7        1             1     0  \n",
       "4            7        1             0     1  \n",
       "..         ...      ...           ...   ...  \n",
       "995         15        1             1     0  \n",
       "996         19        0             1     1  \n",
       "997         14        1             0     0  \n",
       "998          6        0             1     0  \n",
       "999          3        1             0     1  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73a7258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2  ...         20       756  2549     9     7   \n",
       "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
       "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
       "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
       "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
       "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
       "1998    0.1        145        5  ...        336       670   869    18    10   \n",
       "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d81818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             1000 non-null   int64  \n",
      " 1   battery_power  1000 non-null   int64  \n",
      " 2   blue           1000 non-null   int64  \n",
      " 3   clock_speed    1000 non-null   float64\n",
      " 4   dual_sim       1000 non-null   int64  \n",
      " 5   fc             1000 non-null   int64  \n",
      " 6   four_g         1000 non-null   int64  \n",
      " 7   int_memory     1000 non-null   int64  \n",
      " 8   m_dep          1000 non-null   float64\n",
      " 9   mobile_wt      1000 non-null   int64  \n",
      " 10  n_cores        1000 non-null   int64  \n",
      " 11  pc             1000 non-null   int64  \n",
      " 12  px_height      1000 non-null   int64  \n",
      " 13  px_width       1000 non-null   int64  \n",
      " 14  ram            1000 non-null   int64  \n",
      " 15  sc_h           1000 non-null   int64  \n",
      " 16  sc_w           1000 non-null   int64  \n",
      " 17  talk_time      1000 non-null   int64  \n",
      " 18  three_g        1000 non-null   int64  \n",
      " 19  touch_screen   1000 non-null   int64  \n",
      " 20  wifi           1000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 164.2 KB\n"
     ]
    }
   ],
   "source": [
    "datatest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb262933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "datatrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7956e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id  : \n",
      "1       1\n",
      "672     1\n",
      "659     1\n",
      "660     1\n",
      "661     1\n",
      "       ..\n",
      "339     1\n",
      "340     1\n",
      "341     1\n",
      "342     1\n",
      "1000    1\n",
      "Name: id, Length: 1000, dtype: int64\n",
      "battery_power  : \n",
      "1074    5\n",
      "1981    5\n",
      "529     4\n",
      "1745    4\n",
      "1715    4\n",
      "       ..\n",
      "1248    1\n",
      "1392    1\n",
      "1706    1\n",
      "1297    1\n",
      "1185    1\n",
      "Name: battery_power, Length: 721, dtype: int64\n",
      "blue  : \n",
      "1    516\n",
      "0    484\n",
      "Name: blue, dtype: int64\n",
      "clock_speed  : \n",
      "0.5    199\n",
      "0.6     40\n",
      "2.6     40\n",
      "1.4     39\n",
      "2.9     38\n",
      "1.3     38\n",
      "2.1     37\n",
      "1.6     37\n",
      "2.5     36\n",
      "0.9     34\n",
      "2.7     33\n",
      "2.8     33\n",
      "2.4     33\n",
      "1.1     33\n",
      "1.8     32\n",
      "1.7     30\n",
      "2.2     29\n",
      "0.8     29\n",
      "0.7     28\n",
      "2.3     28\n",
      "1.9     28\n",
      "1.5     27\n",
      "1.2     27\n",
      "1.0     26\n",
      "2.0     25\n",
      "3.0     21\n",
      "Name: clock_speed, dtype: int64\n",
      "dual_sim  : \n",
      "1    517\n",
      "0    483\n",
      "Name: dual_sim, dtype: int64\n",
      "fc  : \n",
      "0     210\n",
      "1     124\n",
      "2      97\n",
      "4      80\n",
      "5      74\n",
      "3      70\n",
      "6      59\n",
      "7      50\n",
      "9      41\n",
      "8      38\n",
      "10     37\n",
      "11     29\n",
      "13     21\n",
      "12     17\n",
      "14     16\n",
      "15     12\n",
      "16     11\n",
      "18     10\n",
      "17      2\n",
      "19      2\n",
      "Name: fc, dtype: int64\n",
      "four_g  : \n",
      "0    513\n",
      "1    487\n",
      "Name: four_g, dtype: int64\n",
      "int_memory  : \n",
      "56    27\n",
      "38    26\n",
      "3     24\n",
      "33    24\n",
      "24    24\n",
      "      ..\n",
      "50    10\n",
      "4     10\n",
      "21     9\n",
      "18     9\n",
      "46     7\n",
      "Name: int_memory, Length: 63, dtype: int64\n",
      "m_dep  : \n",
      "0.1    139\n",
      "0.5    122\n",
      "0.9    107\n",
      "0.8    105\n",
      "0.7    101\n",
      "0.6     98\n",
      "0.4     96\n",
      "0.2     95\n",
      "0.3     88\n",
      "1.0     49\n",
      "Name: m_dep, dtype: int64\n",
      "mobile_wt  : \n",
      "83     17\n",
      "174    15\n",
      "128    14\n",
      "141    13\n",
      "171    13\n",
      "       ..\n",
      "176     4\n",
      "96      3\n",
      "84      3\n",
      "142     3\n",
      "126     2\n",
      "Name: mobile_wt, Length: 121, dtype: int64\n",
      "n_cores  : \n",
      "4    142\n",
      "1    138\n",
      "2    134\n",
      "5    130\n",
      "3    127\n",
      "8    121\n",
      "7    107\n",
      "6    101\n",
      "Name: n_cores, dtype: int64\n",
      "pc  : \n",
      "16    59\n",
      "17    58\n",
      "1     57\n",
      "6     56\n",
      "14    55\n",
      "20    55\n",
      "7     52\n",
      "5     52\n",
      "3     51\n",
      "9     48\n",
      "12    46\n",
      "10    44\n",
      "2     43\n",
      "11    42\n",
      "15    42\n",
      "19    41\n",
      "18    41\n",
      "4     41\n",
      "0     40\n",
      "8     40\n",
      "13    37\n",
      "Name: pc, dtype: int64\n",
      "px_height  : \n",
      "98     6\n",
      "185    5\n",
      "35     5\n",
      "633    5\n",
      "346    5\n",
      "      ..\n",
      "117    1\n",
      "636    1\n",
      "388    1\n",
      "234    1\n",
      "38     1\n",
      "Name: px_height, Length: 694, dtype: int64\n",
      "px_width  : \n",
      "555     4\n",
      "1521    4\n",
      "1443    4\n",
      "628     3\n",
      "1386    3\n",
      "       ..\n",
      "1468    1\n",
      "1440    1\n",
      "581     1\n",
      "548     1\n",
      "1632    1\n",
      "Name: px_width, Length: 743, dtype: int64\n",
      "ram  : \n",
      "1435    3\n",
      "3816    3\n",
      "1972    3\n",
      "3386    3\n",
      "2179    3\n",
      "       ..\n",
      "3238    1\n",
      "1266    1\n",
      "1634    1\n",
      "3208    1\n",
      "1223    1\n",
      "Name: ram, Length: 872, dtype: int64\n",
      "sc_h  : \n",
      "5     77\n",
      "17    74\n",
      "13    73\n",
      "15    72\n",
      "14    70\n",
      "11    69\n",
      "9     67\n",
      "8     67\n",
      "16    65\n",
      "12    64\n",
      "19    64\n",
      "6     62\n",
      "7     61\n",
      "18    59\n",
      "10    56\n",
      "Name: sc_h, dtype: int64\n",
      "sc_w  : \n",
      "0     112\n",
      "2     107\n",
      "1      99\n",
      "4      95\n",
      "5      93\n",
      "3      84\n",
      "6      73\n",
      "7      67\n",
      "10     52\n",
      "9      46\n",
      "8      44\n",
      "11     29\n",
      "13     23\n",
      "12     21\n",
      "14     20\n",
      "15     15\n",
      "17      8\n",
      "16      7\n",
      "18      5\n",
      "Name: sc_w, dtype: int64\n",
      "talk_time  : \n",
      "10    74\n",
      "19    66\n",
      "7     59\n",
      "20    57\n",
      "16    56\n",
      "4     55\n",
      "18    54\n",
      "12    54\n",
      "13    54\n",
      "2     51\n",
      "5     51\n",
      "8     50\n",
      "9     49\n",
      "3     49\n",
      "11    48\n",
      "15    46\n",
      "14    46\n",
      "6     44\n",
      "17    37\n",
      "Name: talk_time, dtype: int64\n",
      "three_g  : \n",
      "1    756\n",
      "0    244\n",
      "Name: three_g, dtype: int64\n",
      "touch_screen  : \n",
      "1    500\n",
      "0    500\n",
      "Name: touch_screen, dtype: int64\n",
      "wifi  : \n",
      "1    507\n",
      "0    493\n",
      "Name: wifi, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_features = datatest.select_dtypes(include=['float64','int64'])\n",
    "for column in num_features.columns:\n",
    "    print(column,\" : \")\n",
    "    print(datatest[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f96e3a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery_power  : \n",
      "1872    6\n",
      "618     6\n",
      "1589    6\n",
      "1715    5\n",
      "1807    5\n",
      "       ..\n",
      "660     1\n",
      "1452    1\n",
      "1005    1\n",
      "1372    1\n",
      "858     1\n",
      "Name: battery_power, Length: 1094, dtype: int64\n",
      "blue  : \n",
      "0    1010\n",
      "1     990\n",
      "Name: blue, dtype: int64\n",
      "clock_speed  : \n",
      "0.5    413\n",
      "2.8     85\n",
      "2.3     78\n",
      "2.1     76\n",
      "1.6     76\n",
      "2.5     74\n",
      "0.6     74\n",
      "1.4     70\n",
      "1.3     68\n",
      "1.5     67\n",
      "2.0     67\n",
      "1.9     65\n",
      "0.7     64\n",
      "2.9     62\n",
      "1.8     62\n",
      "1.0     61\n",
      "1.7     60\n",
      "2.2     59\n",
      "0.9     58\n",
      "2.4     58\n",
      "0.8     58\n",
      "1.2     56\n",
      "2.6     55\n",
      "2.7     55\n",
      "1.1     51\n",
      "3.0     28\n",
      "Name: clock_speed, dtype: int64\n",
      "dual_sim  : \n",
      "1    1019\n",
      "0     981\n",
      "Name: dual_sim, dtype: int64\n",
      "fc  : \n",
      "0     474\n",
      "1     245\n",
      "2     189\n",
      "3     170\n",
      "5     139\n",
      "4     133\n",
      "6     112\n",
      "7     100\n",
      "9      78\n",
      "8      77\n",
      "10     62\n",
      "11     51\n",
      "12     45\n",
      "13     40\n",
      "16     24\n",
      "15     23\n",
      "14     20\n",
      "18     11\n",
      "17      6\n",
      "19      1\n",
      "Name: fc, dtype: int64\n",
      "four_g  : \n",
      "1    1043\n",
      "0     957\n",
      "Name: four_g, dtype: int64\n",
      "int_memory  : \n",
      "27    47\n",
      "16    45\n",
      "14    45\n",
      "57    42\n",
      "2     42\n",
      "      ..\n",
      "22    24\n",
      "38    23\n",
      "62    21\n",
      "4     20\n",
      "59    18\n",
      "Name: int_memory, Length: 63, dtype: int64\n",
      "m_dep  : \n",
      "0.1    320\n",
      "0.2    213\n",
      "0.8    208\n",
      "0.5    205\n",
      "0.7    200\n",
      "0.3    199\n",
      "0.9    195\n",
      "0.6    186\n",
      "0.4    168\n",
      "1.0    106\n",
      "Name: m_dep, dtype: int64\n",
      "mobile_wt  : \n",
      "182    28\n",
      "101    27\n",
      "185    27\n",
      "146    26\n",
      "199    26\n",
      "       ..\n",
      "116    10\n",
      "140     9\n",
      "120     9\n",
      "149     9\n",
      "96      9\n",
      "Name: mobile_wt, Length: 121, dtype: int64\n",
      "n_cores  : \n",
      "4    274\n",
      "7    259\n",
      "8    256\n",
      "2    247\n",
      "3    246\n",
      "5    246\n",
      "1    242\n",
      "6    230\n",
      "Name: n_cores, dtype: int64\n",
      "pc  : \n",
      "10    122\n",
      "7     119\n",
      "9     112\n",
      "20    110\n",
      "1     104\n",
      "14    104\n",
      "0     101\n",
      "2      99\n",
      "17     99\n",
      "6      95\n",
      "4      95\n",
      "3      93\n",
      "15     92\n",
      "12     90\n",
      "8      89\n",
      "16     88\n",
      "13     85\n",
      "19     83\n",
      "18     82\n",
      "11     79\n",
      "5      59\n",
      "Name: pc, dtype: int64\n",
      "px_height  : \n",
      "347    7\n",
      "179    6\n",
      "371    6\n",
      "275    6\n",
      "674    5\n",
      "      ..\n",
      "87     1\n",
      "648    1\n",
      "341    1\n",
      "993    1\n",
      "483    1\n",
      "Name: px_height, Length: 1137, dtype: int64\n",
      "px_width  : \n",
      "874     7\n",
      "1247    7\n",
      "1383    6\n",
      "1463    6\n",
      "1469    6\n",
      "       ..\n",
      "1125    1\n",
      "1367    1\n",
      "1569    1\n",
      "1481    1\n",
      "1632    1\n",
      "Name: px_width, Length: 1109, dtype: int64\n",
      "ram  : \n",
      "1464    4\n",
      "3142    4\n",
      "2610    4\n",
      "2227    4\n",
      "1229    4\n",
      "       ..\n",
      "2312    1\n",
      "2167    1\n",
      "3508    1\n",
      "297     1\n",
      "3919    1\n",
      "Name: ram, Length: 1562, dtype: int64\n",
      "sc_h  : \n",
      "17    193\n",
      "12    157\n",
      "7     151\n",
      "16    143\n",
      "14    143\n",
      "15    135\n",
      "13    131\n",
      "11    126\n",
      "10    125\n",
      "9     124\n",
      "19    124\n",
      "18    120\n",
      "8     117\n",
      "6     114\n",
      "5      97\n",
      "Name: sc_h, dtype: int64\n",
      "sc_w  : \n",
      "1     210\n",
      "3     199\n",
      "4     182\n",
      "0     180\n",
      "5     161\n",
      "2     156\n",
      "7     132\n",
      "6     130\n",
      "8     125\n",
      "10    107\n",
      "9      97\n",
      "11     84\n",
      "12     68\n",
      "13     49\n",
      "14     33\n",
      "15     31\n",
      "16     29\n",
      "17     19\n",
      "18      8\n",
      "Name: sc_w, dtype: int64\n",
      "talk_time  : \n",
      "7     124\n",
      "4     123\n",
      "16    116\n",
      "15    115\n",
      "19    113\n",
      "6     111\n",
      "10    105\n",
      "8     104\n",
      "11    103\n",
      "20    102\n",
      "14    101\n",
      "13    100\n",
      "18    100\n",
      "9     100\n",
      "2      99\n",
      "12     99\n",
      "17     98\n",
      "3      94\n",
      "5      93\n",
      "Name: talk_time, dtype: int64\n",
      "three_g  : \n",
      "1    1523\n",
      "0     477\n",
      "Name: three_g, dtype: int64\n",
      "touch_screen  : \n",
      "1    1006\n",
      "0     994\n",
      "Name: touch_screen, dtype: int64\n",
      "wifi  : \n",
      "1    1014\n",
      "0     986\n",
      "Name: wifi, dtype: int64\n",
      "price_range  : \n",
      "1    500\n",
      "2    500\n",
      "3    500\n",
      "0    500\n",
      "Name: price_range, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_features = datatrain.select_dtypes(include=['float64','int64'])\n",
    "for column in num_features.columns:\n",
    "    print(column,\" : \")\n",
    "    print(datatrain[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48bcad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "battery_power    0\n",
       "blue             0\n",
       "clock_speed      0\n",
       "dual_sim         0\n",
       "fc               0\n",
       "four_g           0\n",
       "int_memory       0\n",
       "m_dep            0\n",
       "mobile_wt        0\n",
       "n_cores          0\n",
       "pc               0\n",
       "px_height        0\n",
       "px_width         0\n",
       "ram              0\n",
       "sc_h             0\n",
       "sc_w             0\n",
       "talk_time        0\n",
       "three_g          0\n",
       "touch_screen     0\n",
       "wifi             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Menghitung Missing Values setiap fitur\n",
    "datatest.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8f2d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power    0\n",
       "blue             0\n",
       "clock_speed      0\n",
       "dual_sim         0\n",
       "fc               0\n",
       "four_g           0\n",
       "int_memory       0\n",
       "m_dep            0\n",
       "mobile_wt        0\n",
       "n_cores          0\n",
       "pc               0\n",
       "px_height        0\n",
       "px_width         0\n",
       "ram              0\n",
       "sc_h             0\n",
       "sc_w             0\n",
       "talk_time        0\n",
       "three_g          0\n",
       "touch_screen     0\n",
       "wifi             0\n",
       "price_range      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Menghitung Missing Values setiap fitur\n",
    "datatrain.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c83dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f0b277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatrain.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kolom 'id' bukan target menurut gw, jadi ini gak perlu harusnya\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split into features and target variable\n",
    "X = datatest.drop(['id'], axis=1)\n",
    "y = datatest['id']\n",
    "\n",
    "# Create a Random Forest regressor with 100 trees\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a dataframe of feature importances\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "\n",
    "# Sort the dataframe by importance in descending order\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160775da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          feature  importance\n",
      "13            ram    0.867918\n",
      "0   battery_power    0.051062\n",
      "11      px_height    0.029619\n",
      "12       px_width    0.028545\n",
      "8       mobile_wt    0.004107\n",
      "6      int_memory    0.002617\n",
      "7           m_dep    0.001959\n",
      "15           sc_w    0.001938\n",
      "10             pc    0.001904\n",
      "16      talk_time    0.001896\n",
      "2     clock_speed    0.001676\n",
      "14           sc_h    0.001587\n",
      "4              fc    0.001552\n",
      "9         n_cores    0.001488\n",
      "5          four_g    0.000438\n",
      "17        three_g    0.000384\n",
      "18   touch_screen    0.000351\n",
      "19           wifi    0.000344\n",
      "1            blue    0.000318\n",
      "3        dual_sim    0.000298\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split into features and target variable\n",
    "X = datatrain.drop(['price_range'], axis=1)\n",
    "y = datatrain['price_range']\n",
    "\n",
    "# Create a Random Forest regressor with 100 trees\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a dataframe of feature importances\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "\n",
    "# Sort the dataframe by importance in descending order\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d3120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>...</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021511</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.035917</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.002794</td>\n",
       "      <td>-0.007541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>-0.012138</td>\n",
       "      <td>-0.043442</td>\n",
       "      <td>-0.011972</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>4.957099e-02</td>\n",
       "      <td>3.976791e-02</td>\n",
       "      <td>-0.036643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>battery_power</th>\n",
       "      <td>-0.021511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.046610</td>\n",
       "      <td>-0.039075</td>\n",
       "      <td>-0.061171</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>-0.042520</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>-0.009065</td>\n",
       "      <td>-0.047065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012847</td>\n",
       "      <td>0.048647</td>\n",
       "      <td>0.053365</td>\n",
       "      <td>-0.032366</td>\n",
       "      <td>-0.055665</td>\n",
       "      <td>-0.023905</td>\n",
       "      <td>0.015546</td>\n",
       "      <td>3.151417e-02</td>\n",
       "      <td>-1.013784e-02</td>\n",
       "      <td>-0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.000464</td>\n",
       "      <td>-0.046610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034754</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>-0.056063</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>0.018319</td>\n",
       "      <td>0.023513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025247</td>\n",
       "      <td>-0.058810</td>\n",
       "      <td>-0.032054</td>\n",
       "      <td>0.057570</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>-0.031995</td>\n",
       "      <td>1.352986e-02</td>\n",
       "      <td>-6.003074e-02</td>\n",
       "      <td>0.025568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clock_speed</th>\n",
       "      <td>0.035917</td>\n",
       "      <td>-0.039075</td>\n",
       "      <td>0.034754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012423</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>-0.024665</td>\n",
       "      <td>-0.030487</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>-0.014107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.070585</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>-0.039503</td>\n",
       "      <td>-0.027138</td>\n",
       "      <td>-0.078797</td>\n",
       "      <td>-2.140644e-02</td>\n",
       "      <td>6.189276e-02</td>\n",
       "      <td>-0.048593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_sim</th>\n",
       "      <td>-0.002721</td>\n",
       "      <td>-0.061171</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>-0.012423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057606</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>-0.012158</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073936</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>-0.002064</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>6.895838e-04</td>\n",
       "      <td>3.401967e-02</td>\n",
       "      <td>0.031545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc</th>\n",
       "      <td>0.016934</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>-0.056063</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.057606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-0.006565</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659338</td>\n",
       "      <td>-0.017982</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>-0.051997</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>-0.051458</td>\n",
       "      <td>-1.112104e-02</td>\n",
       "      <td>1.546706e-02</td>\n",
       "      <td>-0.060373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_g</th>\n",
       "      <td>0.030921</td>\n",
       "      <td>-0.042520</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>-0.024665</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037488</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.033655</td>\n",
       "      <td>0.036545</td>\n",
       "      <td>0.030821</td>\n",
       "      <td>-0.015087</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>5.535283e-01</td>\n",
       "      <td>-1.000338e-02</td>\n",
       "      <td>-0.035652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_memory</th>\n",
       "      <td>-0.014023</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>-0.030487</td>\n",
       "      <td>-0.012158</td>\n",
       "      <td>-0.006565</td>\n",
       "      <td>-0.037488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.010447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>-0.009564</td>\n",
       "      <td>-0.003877</td>\n",
       "      <td>-0.007107</td>\n",
       "      <td>-0.009249</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>0.023759</td>\n",
       "      <td>-1.592239e-02</td>\n",
       "      <td>2.218589e-02</td>\n",
       "      <td>0.011860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_dep</th>\n",
       "      <td>-0.002794</td>\n",
       "      <td>-0.009065</td>\n",
       "      <td>0.018319</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012663</td>\n",
       "      <td>0.062559</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>-0.026160</td>\n",
       "      <td>-0.023393</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>-2.927827e-02</td>\n",
       "      <td>4.025363e-02</td>\n",
       "      <td>-0.039705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_wt</th>\n",
       "      <td>-0.007541</td>\n",
       "      <td>-0.047065</td>\n",
       "      <td>0.023513</td>\n",
       "      <td>-0.014107</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.010447</td>\n",
       "      <td>-0.041994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>-0.014577</td>\n",
       "      <td>0.028786</td>\n",
       "      <td>-0.022053</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>6.261881e-03</td>\n",
       "      <td>4.452531e-02</td>\n",
       "      <td>0.069762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_cores</th>\n",
       "      <td>-0.015935</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>-0.012247</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>0.020828</td>\n",
       "      <td>0.066716</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>-0.038908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>-0.054433</td>\n",
       "      <td>-0.059388</td>\n",
       "      <td>-0.042750</td>\n",
       "      <td>-0.034057</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>-0.005640</td>\n",
       "      <td>5.093589e-02</td>\n",
       "      <td>-1.661558e-02</td>\n",
       "      <td>-0.007256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.012847</td>\n",
       "      <td>-0.025247</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>0.073936</td>\n",
       "      <td>0.659338</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>0.012663</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>0.056397</td>\n",
       "      <td>-0.045987</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>-0.038434</td>\n",
       "      <td>-1.522038e-02</td>\n",
       "      <td>2.199588e-02</td>\n",
       "      <td>-0.054955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_height</th>\n",
       "      <td>-0.025056</td>\n",
       "      <td>0.048647</td>\n",
       "      <td>-0.058810</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>-0.017982</td>\n",
       "      <td>0.033655</td>\n",
       "      <td>-0.009564</td>\n",
       "      <td>0.062559</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517650</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.052383</td>\n",
       "      <td>-1.112460e-02</td>\n",
       "      <td>-1.963656e-02</td>\n",
       "      <td>-0.012459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_width</th>\n",
       "      <td>-0.012138</td>\n",
       "      <td>0.053365</td>\n",
       "      <td>-0.032054</td>\n",
       "      <td>0.070585</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.036545</td>\n",
       "      <td>-0.003877</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>-0.014577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056397</td>\n",
       "      <td>0.517650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026378</td>\n",
       "      <td>-0.022610</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.053423</td>\n",
       "      <td>1.943857e-02</td>\n",
       "      <td>-3.998625e-02</td>\n",
       "      <td>-0.073997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram</th>\n",
       "      <td>-0.043442</td>\n",
       "      <td>-0.032366</td>\n",
       "      <td>0.057570</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>-0.051997</td>\n",
       "      <td>0.030821</td>\n",
       "      <td>-0.007107</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.028786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045987</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>-0.026378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.030678</td>\n",
       "      <td>-0.003419</td>\n",
       "      <td>2.971246e-02</td>\n",
       "      <td>-4.365416e-02</td>\n",
       "      <td>-0.031904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_h</th>\n",
       "      <td>-0.011972</td>\n",
       "      <td>-0.055665</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>-0.039503</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>-0.015087</td>\n",
       "      <td>-0.009249</td>\n",
       "      <td>-0.026160</td>\n",
       "      <td>-0.022053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>-0.022610</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497154</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>-1.952833e-02</td>\n",
       "      <td>-1.366232e-02</td>\n",
       "      <td>-0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_w</th>\n",
       "      <td>0.002918</td>\n",
       "      <td>-0.023905</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>-0.027138</td>\n",
       "      <td>-0.002064</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.023393</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.030678</td>\n",
       "      <td>0.497154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>1.155939e-03</td>\n",
       "      <td>-4.766466e-02</td>\n",
       "      <td>0.015475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk_time</th>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.015546</td>\n",
       "      <td>-0.031995</td>\n",
       "      <td>-0.078797</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>-0.051458</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.023759</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038434</td>\n",
       "      <td>0.052383</td>\n",
       "      <td>0.053423</td>\n",
       "      <td>-0.003419</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.805074e-03</td>\n",
       "      <td>2.893599e-02</td>\n",
       "      <td>0.016710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three_g</th>\n",
       "      <td>0.049571</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>-0.021406</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>-0.011121</td>\n",
       "      <td>0.553528</td>\n",
       "      <td>-0.015922</td>\n",
       "      <td>-0.029278</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015220</td>\n",
       "      <td>-0.011125</td>\n",
       "      <td>0.019439</td>\n",
       "      <td>0.029712</td>\n",
       "      <td>-0.019528</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-6.016503e-17</td>\n",
       "      <td>-0.024645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>touch_screen</th>\n",
       "      <td>0.039768</td>\n",
       "      <td>-0.010138</td>\n",
       "      <td>-0.060031</td>\n",
       "      <td>0.061893</td>\n",
       "      <td>0.034020</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>-0.010003</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>0.040254</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021996</td>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.039986</td>\n",
       "      <td>-0.043654</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>-0.047665</td>\n",
       "      <td>0.028936</td>\n",
       "      <td>-6.016503e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.026003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wifi</th>\n",
       "      <td>-0.036643</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>-0.048593</td>\n",
       "      <td>0.031545</td>\n",
       "      <td>-0.060373</td>\n",
       "      <td>-0.035652</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>-0.039705</td>\n",
       "      <td>0.069762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>-0.012459</td>\n",
       "      <td>-0.073997</td>\n",
       "      <td>-0.031904</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>0.016710</td>\n",
       "      <td>-2.464544e-02</td>\n",
       "      <td>-2.600255e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  battery_power      blue  clock_speed  dual_sim  \\\n",
       "id             1.000000      -0.021511  0.000464     0.035917 -0.002721   \n",
       "battery_power -0.021511       1.000000 -0.046610    -0.039075 -0.061171   \n",
       "blue           0.000464      -0.046610  1.000000     0.034754 -0.011100   \n",
       "clock_speed    0.035917      -0.039075  0.034754     1.000000 -0.012423   \n",
       "dual_sim      -0.002721      -0.061171 -0.011100    -0.012423  1.000000   \n",
       "fc             0.016934      -0.007846 -0.056063     0.010127  0.057606   \n",
       "four_g         0.030921      -0.042520 -0.001169    -0.024665  0.024907   \n",
       "int_memory    -0.014023       0.003751 -0.012416    -0.030487 -0.012158   \n",
       "m_dep         -0.002794      -0.009065  0.018319     0.016995  0.021760   \n",
       "mobile_wt     -0.007541      -0.047065  0.023513    -0.014107 -0.001734   \n",
       "n_cores       -0.015935       0.025732  0.003283    -0.012247 -0.003129   \n",
       "pc             0.001969       0.012847 -0.025247     0.047469  0.073936   \n",
       "px_height     -0.025056       0.048647 -0.058810     0.017277  0.006842   \n",
       "px_width      -0.012138       0.053365 -0.032054     0.070585  0.015610   \n",
       "ram           -0.043442      -0.032366  0.057570    -0.000650  0.048171   \n",
       "sc_h          -0.011972      -0.055665  0.012780    -0.039503  0.006295   \n",
       "sc_w           0.002918      -0.023905  0.004223    -0.027138 -0.002064   \n",
       "talk_time      0.030807       0.015546 -0.031995    -0.078797  0.004390   \n",
       "three_g        0.049571       0.031514  0.013530    -0.021406  0.000690   \n",
       "touch_screen   0.039768      -0.010138 -0.060031     0.061893  0.034020   \n",
       "wifi          -0.036643      -0.000414  0.025568    -0.048593  0.031545   \n",
       "\n",
       "                     fc    four_g  int_memory     m_dep  mobile_wt  ...  \\\n",
       "id             0.016934  0.030921   -0.014023 -0.002794  -0.007541  ...   \n",
       "battery_power -0.007846 -0.042520    0.003751 -0.009065  -0.047065  ...   \n",
       "blue          -0.056063 -0.001169   -0.012416  0.018319   0.023513  ...   \n",
       "clock_speed    0.010127 -0.024665   -0.030487  0.016995  -0.014107  ...   \n",
       "dual_sim       0.057606  0.024907   -0.012158  0.021760  -0.001734  ...   \n",
       "fc             1.000000  0.032832   -0.006565  0.020859   0.018353  ...   \n",
       "four_g         0.032832  1.000000   -0.037488  0.014806  -0.000509  ...   \n",
       "int_memory    -0.006565 -0.037488    1.000000 -0.004386  -0.010447  ...   \n",
       "m_dep          0.020859  0.014806   -0.004386  1.000000  -0.041994  ...   \n",
       "mobile_wt      0.018353 -0.000509   -0.010447 -0.041994   1.000000  ...   \n",
       "n_cores        0.020828  0.066716    0.021601  0.010062  -0.038908  ...   \n",
       "pc             0.659338  0.037669    0.022682  0.012663   0.027343  ...   \n",
       "px_height     -0.017982  0.033655   -0.009564  0.062559   0.011157  ...   \n",
       "px_width       0.030550  0.036545   -0.003877  0.034861  -0.014577  ...   \n",
       "ram           -0.051997  0.030821   -0.007107  0.018349   0.028786  ...   \n",
       "sc_h           0.045158 -0.015087   -0.009249 -0.026160  -0.022053  ...   \n",
       "sc_w           0.006115 -0.000893    0.024521 -0.023393   0.022148  ...   \n",
       "talk_time     -0.051458  0.013692    0.023759  0.024124  -0.021704  ...   \n",
       "three_g       -0.011121  0.553528   -0.015922 -0.029278   0.006262  ...   \n",
       "touch_screen   0.015467 -0.010003    0.022186  0.040254   0.044525  ...   \n",
       "wifi          -0.060373 -0.035652    0.011860 -0.039705   0.069762  ...   \n",
       "\n",
       "                     pc  px_height  px_width       ram      sc_h      sc_w  \\\n",
       "id             0.001969  -0.025056 -0.012138 -0.043442 -0.011972  0.002918   \n",
       "battery_power  0.012847   0.048647  0.053365 -0.032366 -0.055665 -0.023905   \n",
       "blue          -0.025247  -0.058810 -0.032054  0.057570  0.012780  0.004223   \n",
       "clock_speed    0.047469   0.017277  0.070585 -0.000650 -0.039503 -0.027138   \n",
       "dual_sim       0.073936   0.006842  0.015610  0.048171  0.006295 -0.002064   \n",
       "fc             0.659338  -0.017982  0.030550 -0.051997  0.045158  0.006115   \n",
       "four_g         0.037669   0.033655  0.036545  0.030821 -0.015087 -0.000893   \n",
       "int_memory     0.022682  -0.009564 -0.003877 -0.007107 -0.009249  0.024521   \n",
       "m_dep          0.012663   0.062559  0.034861  0.018349 -0.026160 -0.023393   \n",
       "mobile_wt      0.027343   0.011157 -0.014577  0.028786 -0.022053  0.022148   \n",
       "n_cores        0.014376  -0.054433 -0.059388 -0.042750 -0.034057  0.012830   \n",
       "pc             1.000000   0.028910  0.056397 -0.045987  0.019738 -0.006316   \n",
       "px_height      0.028910   1.000000  0.517650  0.027945  0.011162  0.043486   \n",
       "px_width       0.056397   0.517650  1.000000 -0.026378 -0.022610  0.004692   \n",
       "ram           -0.045987   0.027945 -0.026378  1.000000  0.022894  0.030678   \n",
       "sc_h           0.019738   0.011162 -0.022610  0.022894  1.000000  0.497154   \n",
       "sc_w          -0.006316   0.043486  0.004692  0.030678  0.497154  1.000000   \n",
       "talk_time     -0.038434   0.052383  0.053423 -0.003419  0.026062  0.063990   \n",
       "three_g       -0.015220  -0.011125  0.019439  0.029712 -0.019528  0.001156   \n",
       "touch_screen   0.021996  -0.019637 -0.039986 -0.043654 -0.013662 -0.047665   \n",
       "wifi          -0.054955  -0.012459 -0.073997 -0.031904 -0.002994  0.015475   \n",
       "\n",
       "               talk_time       three_g  touch_screen      wifi  \n",
       "id              0.030807  4.957099e-02  3.976791e-02 -0.036643  \n",
       "battery_power   0.015546  3.151417e-02 -1.013784e-02 -0.000414  \n",
       "blue           -0.031995  1.352986e-02 -6.003074e-02  0.025568  \n",
       "clock_speed    -0.078797 -2.140644e-02  6.189276e-02 -0.048593  \n",
       "dual_sim        0.004390  6.895838e-04  3.401967e-02  0.031545  \n",
       "fc             -0.051458 -1.112104e-02  1.546706e-02 -0.060373  \n",
       "four_g          0.013692  5.535283e-01 -1.000338e-02 -0.035652  \n",
       "int_memory      0.023759 -1.592239e-02  2.218589e-02  0.011860  \n",
       "m_dep           0.024124 -2.927827e-02  4.025363e-02 -0.039705  \n",
       "mobile_wt      -0.021704  6.261881e-03  4.452531e-02  0.069762  \n",
       "n_cores        -0.005640  5.093589e-02 -1.661558e-02 -0.007256  \n",
       "pc             -0.038434 -1.522038e-02  2.199588e-02 -0.054955  \n",
       "px_height       0.052383 -1.112460e-02 -1.963656e-02 -0.012459  \n",
       "px_width        0.053423  1.943857e-02 -3.998625e-02 -0.073997  \n",
       "ram            -0.003419  2.971246e-02 -4.365416e-02 -0.031904  \n",
       "sc_h            0.026062 -1.952833e-02 -1.366232e-02 -0.002994  \n",
       "sc_w            0.063990  1.155939e-03 -4.766466e-02  0.015475  \n",
       "talk_time       1.000000 -1.805074e-03  2.893599e-02  0.016710  \n",
       "three_g        -0.001805  1.000000e+00 -6.016503e-17 -0.024645  \n",
       "touch_screen    0.028936 -6.016503e-17  1.000000e+00 -0.026003  \n",
       "wifi            0.016710 -2.464544e-02 -2.600255e-02  1.000000  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = datatest.corr()\n",
    "\n",
    "# Print correlation matrix\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47ea4289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>battery_power</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>-0.041847</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>0.034085</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.029727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>-0.008402</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>-0.029959</td>\n",
       "      <td>-0.021421</td>\n",
       "      <td>0.052510</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>-0.010516</td>\n",
       "      <td>-0.008343</td>\n",
       "      <td>0.200723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.011252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>-0.008605</td>\n",
       "      <td>0.036161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>-0.041533</td>\n",
       "      <td>0.026351</td>\n",
       "      <td>-0.002952</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>-0.030236</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>-0.021863</td>\n",
       "      <td>0.020573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clock_speed</th>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>-0.014364</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>-0.005724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014523</td>\n",
       "      <td>-0.009476</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>-0.029078</td>\n",
       "      <td>-0.007378</td>\n",
       "      <td>-0.011432</td>\n",
       "      <td>-0.046433</td>\n",
       "      <td>0.019756</td>\n",
       "      <td>-0.024471</td>\n",
       "      <td>-0.006606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_sim</th>\n",
       "      <td>-0.041847</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029123</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.008979</td>\n",
       "      <td>-0.024658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020875</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.041072</td>\n",
       "      <td>-0.011949</td>\n",
       "      <td>-0.016666</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>-0.014008</td>\n",
       "      <td>-0.017117</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.017444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc</th>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.029123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016560</td>\n",
       "      <td>-0.029133</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>0.023618</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009990</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>-0.012373</td>\n",
       "      <td>-0.006829</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>-0.014828</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>0.021998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_g</th>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>-0.016560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>-0.029706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019236</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>-0.046628</td>\n",
       "      <td>0.584246</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>-0.017620</td>\n",
       "      <td>0.014772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_memory</th>\n",
       "      <td>-0.004004</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.029133</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>-0.034214</td>\n",
       "      <td>-0.028310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>-0.008335</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>-0.002790</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>-0.026999</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.044435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_dep</th>\n",
       "      <td>0.034085</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>-0.014364</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>-0.025348</td>\n",
       "      <td>-0.018388</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>-0.028353</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_wt</th>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.008605</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>-0.008979</td>\n",
       "      <td>0.023618</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>-0.034214</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>-0.033855</td>\n",
       "      <td>-0.020761</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>-0.014368</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.030302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_cores</th>\n",
       "      <td>-0.029727</td>\n",
       "      <td>0.036161</td>\n",
       "      <td>-0.005724</td>\n",
       "      <td>-0.024658</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>-0.029706</td>\n",
       "      <td>-0.028310</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>-0.014733</td>\n",
       "      <td>0.023774</td>\n",
       "      <td>-0.009964</td>\n",
       "      <td>0.004399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>0.031441</td>\n",
       "      <td>-0.009952</td>\n",
       "      <td>-0.005245</td>\n",
       "      <td>-0.017143</td>\n",
       "      <td>0.644595</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>-0.033273</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.018844</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018465</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>-0.023819</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>-0.008742</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.033599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_height</th>\n",
       "      <td>0.014901</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>-0.014523</td>\n",
       "      <td>-0.020875</td>\n",
       "      <td>-0.009990</td>\n",
       "      <td>-0.019236</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>-0.020352</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>-0.010645</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>0.148858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_width</th>\n",
       "      <td>-0.008402</td>\n",
       "      <td>-0.041533</td>\n",
       "      <td>-0.009476</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>-0.008335</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.165818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram</th>\n",
       "      <td>-0.000653</td>\n",
       "      <td>0.026351</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.041072</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020352</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.917046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_h</th>\n",
       "      <td>-0.029959</td>\n",
       "      <td>-0.002952</td>\n",
       "      <td>-0.029078</td>\n",
       "      <td>-0.011949</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>-0.025348</td>\n",
       "      <td>-0.033855</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506144</td>\n",
       "      <td>-0.017335</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>0.022986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_w</th>\n",
       "      <td>-0.021421</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>-0.007378</td>\n",
       "      <td>-0.016666</td>\n",
       "      <td>-0.012373</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>-0.018388</td>\n",
       "      <td>-0.020761</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.506144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022821</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.035423</td>\n",
       "      <td>0.038711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk_time</th>\n",
       "      <td>0.052510</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>-0.011432</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>-0.006829</td>\n",
       "      <td>-0.046628</td>\n",
       "      <td>-0.002790</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010645</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>-0.017335</td>\n",
       "      <td>-0.022821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042688</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>-0.029504</td>\n",
       "      <td>0.021859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three_g</th>\n",
       "      <td>0.011522</td>\n",
       "      <td>-0.030236</td>\n",
       "      <td>-0.046433</td>\n",
       "      <td>-0.014008</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.584246</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>-0.014733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>-0.042688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.023611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>touch_screen</th>\n",
       "      <td>-0.010516</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.019756</td>\n",
       "      <td>-0.017117</td>\n",
       "      <td>-0.014828</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>-0.026999</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>-0.014368</td>\n",
       "      <td>0.023774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>-0.030411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wifi</th>\n",
       "      <td>-0.008343</td>\n",
       "      <td>-0.021863</td>\n",
       "      <td>-0.024471</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>-0.017620</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>-0.028353</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.009964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>0.035423</td>\n",
       "      <td>-0.029504</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_range</th>\n",
       "      <td>0.200723</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>-0.006606</td>\n",
       "      <td>0.017444</td>\n",
       "      <td>0.021998</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>0.044435</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>-0.030302</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148858</td>\n",
       "      <td>0.165818</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>0.038711</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.023611</td>\n",
       "      <td>-0.030411</td>\n",
       "      <td>0.018785</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               battery_power      blue  clock_speed  dual_sim        fc  \\\n",
       "battery_power       1.000000  0.011252     0.011482 -0.041847  0.033334   \n",
       "blue                0.011252  1.000000     0.021419  0.035198  0.003593   \n",
       "clock_speed         0.011482  0.021419     1.000000 -0.001315 -0.000434   \n",
       "dual_sim           -0.041847  0.035198    -0.001315  1.000000 -0.029123   \n",
       "fc                  0.033334  0.003593    -0.000434 -0.029123  1.000000   \n",
       "four_g              0.015665  0.013443    -0.043073  0.003187 -0.016560   \n",
       "int_memory         -0.004004  0.041177     0.006545 -0.015679 -0.029133   \n",
       "m_dep               0.034085  0.004049    -0.014364 -0.022142 -0.001791   \n",
       "mobile_wt           0.001844 -0.008605     0.012350 -0.008979  0.023618   \n",
       "n_cores            -0.029727  0.036161    -0.005724 -0.024658 -0.013356   \n",
       "pc                  0.031441 -0.009952    -0.005245 -0.017143  0.644595   \n",
       "px_height           0.014901 -0.006872    -0.014523 -0.020875 -0.009990   \n",
       "px_width           -0.008402 -0.041533    -0.009476  0.014291 -0.005176   \n",
       "ram                -0.000653  0.026351     0.003443  0.041072  0.015099   \n",
       "sc_h               -0.029959 -0.002952    -0.029078 -0.011949 -0.011014   \n",
       "sc_w               -0.021421  0.000613    -0.007378 -0.016666 -0.012373   \n",
       "talk_time           0.052510  0.013934    -0.011432 -0.039404 -0.006829   \n",
       "three_g             0.011522 -0.030236    -0.046433 -0.014008  0.001793   \n",
       "touch_screen       -0.010516  0.010061     0.019756 -0.017117 -0.014828   \n",
       "wifi               -0.008343 -0.021863    -0.024471  0.022740  0.020085   \n",
       "price_range         0.200723  0.020573    -0.006606  0.017444  0.021998   \n",
       "\n",
       "                 four_g  int_memory     m_dep  mobile_wt   n_cores  ...  \\\n",
       "battery_power  0.015665   -0.004004  0.034085   0.001844 -0.029727  ...   \n",
       "blue           0.013443    0.041177  0.004049  -0.008605  0.036161  ...   \n",
       "clock_speed   -0.043073    0.006545 -0.014364   0.012350 -0.005724  ...   \n",
       "dual_sim       0.003187   -0.015679 -0.022142  -0.008979 -0.024658  ...   \n",
       "fc            -0.016560   -0.029133 -0.001791   0.023618 -0.013356  ...   \n",
       "four_g         1.000000    0.008690 -0.001823  -0.016537 -0.029706  ...   \n",
       "int_memory     0.008690    1.000000  0.006886  -0.034214 -0.028310  ...   \n",
       "m_dep         -0.001823    0.006886  1.000000   0.021756 -0.003504  ...   \n",
       "mobile_wt     -0.016537   -0.034214  0.021756   1.000000 -0.018989  ...   \n",
       "n_cores       -0.029706   -0.028310 -0.003504  -0.018989  1.000000  ...   \n",
       "pc            -0.005598   -0.033273  0.026282   0.018844 -0.001193  ...   \n",
       "px_height     -0.019236    0.010441  0.025263   0.000939 -0.006872  ...   \n",
       "px_width       0.007448   -0.008335  0.023566   0.000090  0.024480  ...   \n",
       "ram            0.007313    0.032813 -0.009434  -0.002581  0.004868  ...   \n",
       "sc_h           0.027166    0.037771 -0.025348  -0.033855 -0.000315  ...   \n",
       "sc_w           0.037005    0.011731 -0.018388  -0.020761  0.025826  ...   \n",
       "talk_time     -0.046628   -0.002790  0.017003   0.006209  0.013148  ...   \n",
       "three_g        0.584246   -0.009366 -0.012065   0.001551 -0.014733  ...   \n",
       "touch_screen   0.016758   -0.026999 -0.002638  -0.014368  0.023774  ...   \n",
       "wifi          -0.017620    0.006993 -0.028353  -0.000409 -0.009964  ...   \n",
       "price_range    0.014772    0.044435  0.000853  -0.030302  0.004399  ...   \n",
       "\n",
       "               px_height  px_width       ram      sc_h      sc_w  talk_time  \\\n",
       "battery_power   0.014901 -0.008402 -0.000653 -0.029959 -0.021421   0.052510   \n",
       "blue           -0.006872 -0.041533  0.026351 -0.002952  0.000613   0.013934   \n",
       "clock_speed    -0.014523 -0.009476  0.003443 -0.029078 -0.007378  -0.011432   \n",
       "dual_sim       -0.020875  0.014291  0.041072 -0.011949 -0.016666  -0.039404   \n",
       "fc             -0.009990 -0.005176  0.015099 -0.011014 -0.012373  -0.006829   \n",
       "four_g         -0.019236  0.007448  0.007313  0.027166  0.037005  -0.046628   \n",
       "int_memory      0.010441 -0.008335  0.032813  0.037771  0.011731  -0.002790   \n",
       "m_dep           0.025263  0.023566 -0.009434 -0.025348 -0.018388   0.017003   \n",
       "mobile_wt       0.000939  0.000090 -0.002581 -0.033855 -0.020761   0.006209   \n",
       "n_cores        -0.006872  0.024480  0.004868 -0.000315  0.025826   0.013148   \n",
       "pc             -0.018465  0.004196  0.028984  0.004938 -0.023819   0.014657   \n",
       "px_height       1.000000  0.510664 -0.020352  0.059615  0.043038  -0.010645   \n",
       "px_width        0.510664  1.000000  0.004105  0.021599  0.034699   0.006720   \n",
       "ram            -0.020352  0.004105  1.000000  0.015996  0.035576   0.010820   \n",
       "sc_h            0.059615  0.021599  0.015996  1.000000  0.506144  -0.017335   \n",
       "sc_w            0.043038  0.034699  0.035576  0.506144  1.000000  -0.022821   \n",
       "talk_time      -0.010645  0.006720  0.010820 -0.017335 -0.022821   1.000000   \n",
       "three_g        -0.031174  0.000350  0.015795  0.012033  0.030941  -0.042688   \n",
       "touch_screen    0.021891 -0.001628 -0.030455 -0.020023  0.012720   0.017196   \n",
       "wifi            0.051824  0.030319  0.022669  0.025929  0.035423  -0.029504   \n",
       "price_range     0.148858  0.165818  0.917046  0.022986  0.038711   0.021859   \n",
       "\n",
       "                three_g  touch_screen      wifi  price_range  \n",
       "battery_power  0.011522     -0.010516 -0.008343     0.200723  \n",
       "blue          -0.030236      0.010061 -0.021863     0.020573  \n",
       "clock_speed   -0.046433      0.019756 -0.024471    -0.006606  \n",
       "dual_sim      -0.014008     -0.017117  0.022740     0.017444  \n",
       "fc             0.001793     -0.014828  0.020085     0.021998  \n",
       "four_g         0.584246      0.016758 -0.017620     0.014772  \n",
       "int_memory    -0.009366     -0.026999  0.006993     0.044435  \n",
       "m_dep         -0.012065     -0.002638 -0.028353     0.000853  \n",
       "mobile_wt      0.001551     -0.014368 -0.000409    -0.030302  \n",
       "n_cores       -0.014733      0.023774 -0.009964     0.004399  \n",
       "pc            -0.001322     -0.008742  0.005389     0.033599  \n",
       "px_height     -0.031174      0.021891  0.051824     0.148858  \n",
       "px_width       0.000350     -0.001628  0.030319     0.165818  \n",
       "ram            0.015795     -0.030455  0.022669     0.917046  \n",
       "sc_h           0.012033     -0.020023  0.025929     0.022986  \n",
       "sc_w           0.030941      0.012720  0.035423     0.038711  \n",
       "talk_time     -0.042688      0.017196 -0.029504     0.021859  \n",
       "three_g        1.000000      0.013917  0.004316     0.023611  \n",
       "touch_screen   0.013917      1.000000  0.011917    -0.030411  \n",
       "wifi           0.004316      0.011917  1.000000     0.018785  \n",
       "price_range    0.023611     -0.030411  0.018785     1.000000  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix1 = datatrain.corr()\n",
    "\n",
    "# Print correlation matrix\n",
    "corr_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kolom 'id' bukan target menurut gw, jadi ini gak perlu harusnya\n",
    "# Mengecek kolom/fitur terpenting berdasarkan importance dan korelasi\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = datatest.drop(['id'], axis=1).corr()\n",
    "\n",
    "# Set threshold values for importance and correlation\n",
    "importance_threshold = 0.05\n",
    "correlation_threshold = 0.8\n",
    "\n",
    "# Identify columns to keep based on importance and correlation\n",
    "important_columns = feature_importances[feature_importances['importance'] >= importance_threshold]['feature']\n",
    "correlated_columns = set()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix.iloc[i, j] >= correlation_threshold:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            correlated_columns.add(colname)\n",
    "\n",
    "# Remove columns that are not important or highly correlated with others\n",
    "columns_to_drop = set(X.columns) - set(important_columns) - correlated_columns\n",
    "X = X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Print the remaining columns\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89041e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['battery_power', 'ram'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Mengecek kolom/fitur terpenting berdasarkan importance dan korelasi\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix1 = datatrain.drop(['price_range'], axis=1).corr()\n",
    "\n",
    "# Set threshold values for importance and correlation\n",
    "importance_threshold = 0.05\n",
    "correlation_threshold = 0.8\n",
    "\n",
    "# Identify columns to keep based on importance and correlation\n",
    "important_columns = feature_importances[feature_importances['importance'] >= importance_threshold]['feature']\n",
    "correlated_columns = set()\n",
    "for i in range(len(corr_matrix1.columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix1.iloc[i, j] >= correlation_threshold:\n",
    "            colname = corr_matrix1.columns[i]\n",
    "            correlated_columns.add(colname)\n",
    "\n",
    "# Remove columns that are not important or highly correlated with others\n",
    "columns_to_drop = set(X.columns) - set(important_columns) - correlated_columns\n",
    "X = X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Print the remaining columns\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da0303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek kolom/fitur terpenting berdasarkan importance dan korelasi\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix2 = datatest.drop(['id'], axis=1).corr()\n",
    "\n",
    "# Set threshold values for importance and correlation\n",
    "correlation_threshold = 0.8\n",
    "\n",
    "# Identify columns to keep based on importance and correlation\n",
    "correlated_columns = set()\n",
    "for i in range(len(corr_matrix2.columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix2.iloc[i, j] >= correlation_threshold:\n",
    "            colname = corr_matrix2.columns[i]\n",
    "            correlated_columns.add(colname)\n",
    "\n",
    "# Remove columns that are not important or highly correlated with others\n",
    "columns_to_drop = set(X.columns) - correlated_columns\n",
    "X = X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Print the remaining columns\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek kolom/fitur terpenting berdasarkan korelasi saja\n",
    "\n",
    "# menghitung matriks korelasi\n",
    "corr_matrix3 = datatrain.drop(['price_range'], axis=1).corr()\n",
    "\n",
    "# Meng-set nilai threshold untuk korelasi\n",
    "correlation_threshold = 0.8\n",
    "\n",
    "# Identifikasi kolom yang disimpan berdasarkan korelasi\n",
    "correlated_columns = set()\n",
    "for i in range(len(corr_matrix3.columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix3.iloc[i, j] >= correlation_threshold:\n",
    "            colname = corr_matrix3.columns[i]\n",
    "            correlated_columns.add(colname)\n",
    "\n",
    "# Menghapus kolom yang tidak penting/berkorelasi tinggi\n",
    "columns_to_drop = set(X.columns) - correlated_columns\n",
    "X = X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Print kolom yang ada\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a9d00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop fitur id yang dinilai tidak relevan dengan pembuatan model nanti\n",
    "datatest.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c82ee12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1043</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>226</td>\n",
       "      <td>1412</td>\n",
       "      <td>3476</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>746</td>\n",
       "      <td>857</td>\n",
       "      <td>3895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1270</td>\n",
       "      <td>1366</td>\n",
       "      <td>2396</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>295</td>\n",
       "      <td>1752</td>\n",
       "      <td>3893</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>749</td>\n",
       "      <td>810</td>\n",
       "      <td>1773</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1700</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>644</td>\n",
       "      <td>913</td>\n",
       "      <td>2121</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1152</td>\n",
       "      <td>1632</td>\n",
       "      <td>1933</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>477</td>\n",
       "      <td>825</td>\n",
       "      <td>1223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>832</td>\n",
       "      <td>2509</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>457</td>\n",
       "      <td>608</td>\n",
       "      <td>2828</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0             1043     1          1.8         1  14       0           5   \n",
       "1              841     1          0.5         1   4       1          61   \n",
       "2             1807     1          2.8         0   1       0          27   \n",
       "3             1546     0          0.5         1  18       1          25   \n",
       "4             1434     0          1.4         0  11       1          49   \n",
       "..             ...   ...          ...       ...  ..     ...         ...   \n",
       "995           1700     1          1.9         0   0       1          54   \n",
       "996            609     0          1.8         1   0       0          13   \n",
       "997           1185     0          1.4         0   1       1           8   \n",
       "998           1533     1          0.5         1   0       0          50   \n",
       "999           1270     1          0.5         0   4       1          35   \n",
       "\n",
       "     m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0      0.1        193        3  16        226      1412  3476    12     7   \n",
       "1      0.8        191        5  12        746       857  3895     6     0   \n",
       "2      0.9        186        3   4       1270      1366  2396    17    10   \n",
       "3      0.5         96        8  20        295      1752  3893    10     0   \n",
       "4      0.5        108        6  18        749       810  1773    15     8   \n",
       "..     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "995    0.5        170        7  17        644       913  2121    14     8   \n",
       "996    0.9        186        4   2       1152      1632  1933     8     1   \n",
       "997    0.5         80        1  12        477       825  1223     5     0   \n",
       "998    0.4        171        2  12         38       832  2509    15    11   \n",
       "999    0.1        140        6  19        457       608  2828     9     2   \n",
       "\n",
       "     talk_time  three_g  touch_screen  wifi  \n",
       "0            2        0             1     0  \n",
       "1            7        1             0     0  \n",
       "2           10        0             1     1  \n",
       "3            7        1             1     0  \n",
       "4            7        1             0     1  \n",
       "..         ...      ...           ...   ...  \n",
       "995         15        1             1     0  \n",
       "996         19        0             1     1  \n",
       "997         14        1             0     0  \n",
       "998          6        0             1     0  \n",
       "999          3        1             0     1  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affdcab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1248.510000</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>1.540900</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>4.593000</td>\n",
       "      <td>0.487000</td>\n",
       "      <td>33.652000</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>139.51100</td>\n",
       "      <td>4.328000</td>\n",
       "      <td>10.054000</td>\n",
       "      <td>627.121000</td>\n",
       "      <td>1239.774000</td>\n",
       "      <td>2138.998000</td>\n",
       "      <td>11.995000</td>\n",
       "      <td>5.316000</td>\n",
       "      <td>11.085000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>432.458227</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.499961</td>\n",
       "      <td>4.463325</td>\n",
       "      <td>0.500081</td>\n",
       "      <td>18.128694</td>\n",
       "      <td>0.280861</td>\n",
       "      <td>34.85155</td>\n",
       "      <td>2.288155</td>\n",
       "      <td>6.095099</td>\n",
       "      <td>432.929699</td>\n",
       "      <td>439.670981</td>\n",
       "      <td>1088.092278</td>\n",
       "      <td>4.320607</td>\n",
       "      <td>4.240062</td>\n",
       "      <td>5.497636</td>\n",
       "      <td>0.429708</td>\n",
       "      <td>0.50025</td>\n",
       "      <td>0.500201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>895.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>109.75000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>263.750000</td>\n",
       "      <td>831.750000</td>\n",
       "      <td>1237.250000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1246.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>139.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>564.500000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>2153.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1629.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>903.000000</td>\n",
       "      <td>1637.750000</td>\n",
       "      <td>3065.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1907.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3989.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power         blue  clock_speed     dual_sim           fc  \\\n",
       "count    1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     1248.510000     0.516000     1.540900     0.517000     4.593000   \n",
       "std       432.458227     0.499994     0.829268     0.499961     4.463325   \n",
       "min       500.000000     0.000000     0.500000     0.000000     0.000000   \n",
       "25%       895.000000     0.000000     0.700000     0.000000     1.000000   \n",
       "50%      1246.500000     1.000000     1.500000     1.000000     3.000000   \n",
       "75%      1629.250000     1.000000     2.300000     1.000000     7.000000   \n",
       "max      1999.000000     1.000000     3.000000     1.000000    19.000000   \n",
       "\n",
       "            four_g   int_memory        m_dep   mobile_wt      n_cores  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.00000  1000.000000   \n",
       "mean      0.487000    33.652000     0.517500   139.51100     4.328000   \n",
       "std       0.500081    18.128694     0.280861    34.85155     2.288155   \n",
       "min       0.000000     2.000000     0.100000    80.00000     1.000000   \n",
       "25%       0.000000    18.000000     0.300000   109.75000     2.000000   \n",
       "50%       0.000000    34.500000     0.500000   139.00000     4.000000   \n",
       "75%       1.000000    49.000000     0.800000   170.00000     6.000000   \n",
       "max       1.000000    64.000000     1.000000   200.00000     8.000000   \n",
       "\n",
       "                pc    px_height     px_width          ram         sc_h  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     10.054000   627.121000  1239.774000  2138.998000    11.995000   \n",
       "std       6.095099   432.929699   439.670981  1088.092278     4.320607   \n",
       "min       0.000000     0.000000   501.000000   263.000000     5.000000   \n",
       "25%       5.000000   263.750000   831.750000  1237.250000     8.000000   \n",
       "50%      10.000000   564.500000  1250.000000  2153.500000    12.000000   \n",
       "75%      16.000000   903.000000  1637.750000  3065.500000    16.000000   \n",
       "max      20.000000  1907.000000  1998.000000  3989.000000    19.000000   \n",
       "\n",
       "              sc_w    talk_time      three_g  touch_screen         wifi  \n",
       "count  1000.000000  1000.000000  1000.000000    1000.00000  1000.000000  \n",
       "mean      5.316000    11.085000     0.756000       0.50000     0.507000  \n",
       "std       4.240062     5.497636     0.429708       0.50025     0.500201  \n",
       "min       0.000000     2.000000     0.000000       0.00000     0.000000  \n",
       "25%       2.000000     6.750000     1.000000       0.00000     0.000000  \n",
       "50%       5.000000    11.000000     1.000000       0.50000     1.000000  \n",
       "75%       8.000000    16.000000     1.000000       1.00000     1.000000  \n",
       "max      18.000000    20.000000     1.000000       1.00000     1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4473bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1238.518500</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>1.522250</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>4.309500</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>32.046500</td>\n",
       "      <td>0.501750</td>\n",
       "      <td>140.249000</td>\n",
       "      <td>4.520500</td>\n",
       "      <td>...</td>\n",
       "      <td>645.108000</td>\n",
       "      <td>1251.515500</td>\n",
       "      <td>2124.213000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>5.767000</td>\n",
       "      <td>11.011000</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>439.418206</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>4.341444</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>...</td>\n",
       "      <td>443.780811</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>0.426273</td>\n",
       "      <td>0.500116</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>1.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>851.750000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>874.750000</td>\n",
       "      <td>1207.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2146.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1615.250000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>947.250000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>3064.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3998.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power       blue  clock_speed     dual_sim           fc  \\\n",
       "count    2000.000000  2000.0000  2000.000000  2000.000000  2000.000000   \n",
       "mean     1238.518500     0.4950     1.522250     0.509500     4.309500   \n",
       "std       439.418206     0.5001     0.816004     0.500035     4.341444   \n",
       "min       501.000000     0.0000     0.500000     0.000000     0.000000   \n",
       "25%       851.750000     0.0000     0.700000     0.000000     1.000000   \n",
       "50%      1226.000000     0.0000     1.500000     1.000000     3.000000   \n",
       "75%      1615.250000     1.0000     2.200000     1.000000     7.000000   \n",
       "max      1998.000000     1.0000     3.000000     1.000000    19.000000   \n",
       "\n",
       "            four_g   int_memory        m_dep    mobile_wt      n_cores  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.521500    32.046500     0.501750   140.249000     4.520500  ...   \n",
       "std       0.499662    18.145715     0.288416    35.399655     2.287837  ...   \n",
       "min       0.000000     2.000000     0.100000    80.000000     1.000000  ...   \n",
       "25%       0.000000    16.000000     0.200000   109.000000     3.000000  ...   \n",
       "50%       1.000000    32.000000     0.500000   141.000000     4.000000  ...   \n",
       "75%       1.000000    48.000000     0.800000   170.000000     7.000000  ...   \n",
       "max       1.000000    64.000000     1.000000   200.000000     8.000000  ...   \n",
       "\n",
       "         px_height     px_width          ram         sc_h         sc_w  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    645.108000  1251.515500  2124.213000    12.306500     5.767000   \n",
       "std     443.780811   432.199447  1084.732044     4.213245     4.356398   \n",
       "min       0.000000   500.000000   256.000000     5.000000     0.000000   \n",
       "25%     282.750000   874.750000  1207.500000     9.000000     2.000000   \n",
       "50%     564.000000  1247.000000  2146.500000    12.000000     5.000000   \n",
       "75%     947.250000  1633.000000  3064.500000    16.000000     9.000000   \n",
       "max    1960.000000  1998.000000  3998.000000    19.000000    18.000000   \n",
       "\n",
       "         talk_time      three_g  touch_screen         wifi  price_range  \n",
       "count  2000.000000  2000.000000   2000.000000  2000.000000  2000.000000  \n",
       "mean     11.011000     0.761500      0.503000     0.507000     1.500000  \n",
       "std       5.463955     0.426273      0.500116     0.500076     1.118314  \n",
       "min       2.000000     0.000000      0.000000     0.000000     0.000000  \n",
       "25%       6.000000     1.000000      0.000000     0.000000     0.750000  \n",
       "50%      11.000000     1.000000      1.000000     1.000000     1.500000  \n",
       "75%      16.000000     1.000000      1.000000     1.000000     2.250000  \n",
       "max      20.000000     1.000000      1.000000     1.000000     3.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot datanya\n",
    "import matplotlib.pyplot as plt\n",
    "pd.plotting.scatter_matrix(datatest, figsize=(100,100)) # plot the data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot datanya\n",
    "import matplotlib.pyplot as plt\n",
    "pd.plotting.scatter_matrix(datatrain, figsize=(100,100)) # plot the data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b57a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap datanya\n",
    "import seaborn as sns\n",
    "\n",
    "corr = datatest.corr()\n",
    "plt.subplots(figsize=(100,100))\n",
    "sns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c362b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap datanya\n",
    "import seaborn as sns\n",
    "\n",
    "corr = datatrain.corr()\n",
    "plt.subplots(figsize=(100,100))\n",
    "sns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18fe4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek apakah data mengandung NaN value\n",
    "import pandas as pd\n",
    "\n",
    "nan_mask = datatest.isna()  # membuat masker boolean untuk melihat letak/lokasi NaN value\n",
    "if nan_mask.any().any():\n",
    "    print(\"Data contains NaN values.\")\n",
    "    datatest.fillna(datatest.mean(), inplace=True)  # imputasi observasi NaN dengan nilai mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50e0c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek apakah data mengandung NaN value\n",
    "import pandas as pd\n",
    "\n",
    "nan_mask = datatrain.isna()  # membuat masker boolean untuk melihat letak/lokasi NaN value\n",
    "if nan_mask.any().any():\n",
    "    print(\"Data contains NaN values.\")\n",
    "    datatrain.fillna(datatrain.mean(), inplace=True)  # imputasi observasi NaN dengan nilai mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00e34826",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datatrain.drop('price_range',axis=1).copy()\n",
    "Y = datatrain.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "201bd19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2   2         20       756  2549     9     7   \n",
       "1       0.7        136        3   6        905      1988  2631    17     3   \n",
       "2       0.9        145        5   6       1263      1716  2603    11     2   \n",
       "3       0.8        131        6   9       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  14       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  14       1222      1890   668    13     4   \n",
       "1996    0.2        187        4   3        915      1965  2032    11    10   \n",
       "1997    0.7        108        8   3        868      1632  3057     9     1   \n",
       "1998    0.1        145        5   5        336       670   869    18    10   \n",
       "1999    0.9        168        6  16        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  \n",
       "0            19        0             0     1  \n",
       "1             7        1             1     0  \n",
       "2             9        1             1     0  \n",
       "3            11        1             0     0  \n",
       "4            15        1             1     0  \n",
       "...         ...      ...           ...   ...  \n",
       "1995         19        1             1     0  \n",
       "1996         16        1             1     1  \n",
       "1997          5        1             1     0  \n",
       "1998         19        1             1     1  \n",
       "1999          2        1             1     1  \n",
       "\n",
       "[2000 rows x 20 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91f15e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price_range\n",
       "0               1\n",
       "1               2\n",
       "2               2\n",
       "3               2\n",
       "4               1\n",
       "...           ...\n",
       "1995            0\n",
       "1996            2\n",
       "1997            3\n",
       "1998            0\n",
       "1999            3\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f6c0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X\n",
    "y_train = Y\n",
    "x_test = datatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efb15de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2   2         20       756  2549     9     7   \n",
       "1       0.7        136        3   6        905      1988  2631    17     3   \n",
       "2       0.9        145        5   6       1263      1716  2603    11     2   \n",
       "3       0.8        131        6   9       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  14       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  14       1222      1890   668    13     4   \n",
       "1996    0.2        187        4   3        915      1965  2032    11    10   \n",
       "1997    0.7        108        8   3        868      1632  3057     9     1   \n",
       "1998    0.1        145        5   5        336       670   869    18    10   \n",
       "1999    0.9        168        6  16        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  \n",
       "0            19        0             0     1  \n",
       "1             7        1             1     0  \n",
       "2             9        1             1     0  \n",
       "3            11        1             0     0  \n",
       "4            15        1             1     0  \n",
       "...         ...      ...           ...   ...  \n",
       "1995         19        1             1     0  \n",
       "1996         16        1             1     1  \n",
       "1997          5        1             1     0  \n",
       "1998         19        1             1     1  \n",
       "1999          2        1             1     1  \n",
       "\n",
       "[2000 rows x 20 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf9f1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1043</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>226</td>\n",
       "      <td>1412</td>\n",
       "      <td>3476</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>746</td>\n",
       "      <td>857</td>\n",
       "      <td>3895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1270</td>\n",
       "      <td>1366</td>\n",
       "      <td>2396</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>295</td>\n",
       "      <td>1752</td>\n",
       "      <td>3893</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>749</td>\n",
       "      <td>810</td>\n",
       "      <td>1773</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1700</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>644</td>\n",
       "      <td>913</td>\n",
       "      <td>2121</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1152</td>\n",
       "      <td>1632</td>\n",
       "      <td>1933</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>477</td>\n",
       "      <td>825</td>\n",
       "      <td>1223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>832</td>\n",
       "      <td>2509</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>457</td>\n",
       "      <td>608</td>\n",
       "      <td>2828</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0             1043     1          1.8         1  14       0           5   \n",
       "1              841     1          0.5         1   4       1          61   \n",
       "2             1807     1          2.8         0   1       0          27   \n",
       "3             1546     0          0.5         1  18       1          25   \n",
       "4             1434     0          1.4         0  11       1          49   \n",
       "..             ...   ...          ...       ...  ..     ...         ...   \n",
       "995           1700     1          1.9         0   0       1          54   \n",
       "996            609     0          1.8         1   0       0          13   \n",
       "997           1185     0          1.4         0   1       1           8   \n",
       "998           1533     1          0.5         1   0       0          50   \n",
       "999           1270     1          0.5         0   4       1          35   \n",
       "\n",
       "     m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0      0.1        193        3  16        226      1412  3476    12     7   \n",
       "1      0.8        191        5  12        746       857  3895     6     0   \n",
       "2      0.9        186        3   4       1270      1366  2396    17    10   \n",
       "3      0.5         96        8  20        295      1752  3893    10     0   \n",
       "4      0.5        108        6  18        749       810  1773    15     8   \n",
       "..     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "995    0.5        170        7  17        644       913  2121    14     8   \n",
       "996    0.9        186        4   2       1152      1632  1933     8     1   \n",
       "997    0.5         80        1  12        477       825  1223     5     0   \n",
       "998    0.4        171        2  12         38       832  2509    15    11   \n",
       "999    0.1        140        6  19        457       608  2828     9     2   \n",
       "\n",
       "     talk_time  three_g  touch_screen  wifi  \n",
       "0            2        0             1     0  \n",
       "1            7        1             0     0  \n",
       "2           10        0             1     1  \n",
       "3            7        1             1     0  \n",
       "4            7        1             0     1  \n",
       "..         ...      ...           ...   ...  \n",
       "995         15        1             1     0  \n",
       "996         19        0             1     1  \n",
       "997         14        1             0     0  \n",
       "998          6        0             1     0  \n",
       "999          3        1             0     1  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2814869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price_range\n",
       "0               1\n",
       "1               2\n",
       "2               2\n",
       "3               2\n",
       "4               1\n",
       "...           ...\n",
       "1995            0\n",
       "1996            2\n",
       "1997            3\n",
       "1998            0\n",
       "1999            3\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecb84ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regr = LogisticRegression()\n",
    "svc = SVC()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62c9752a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# melakukan cross validation pada masing-masing metode\n",
    "lr_score = cross_val_score(log_regr, x_train, y_train, cv=kfold,error_score=\"raise\").mean()\n",
    "svc_score = cross_val_score(svc, x_train, y_train, cv=kfold, error_score=\"raise\").mean()\n",
    "dt_score = cross_val_score(dt, x_train, y_train, cv=kfold, error_score=\"raise\").mean()\n",
    "rf_score = cross_val_score(rf, x_train, y_train, cv=kfold, error_score=\"raise\").mean()\n",
    "#ini kalo ada warning 'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.' berarti yang logistic regression gak konvergen bahkan sampe nyentuh max_iter, saran gw coba nambah max_iter nya atau yah gak usah pake logistic sama sekali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ee5e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6365000000000001\n",
      "0.9515\n",
      "0.8324999999999999\n",
      "0.883\n"
     ]
    }
   ],
   "source": [
    "for i in [lr_score, svc_score, dt_score, rf_score]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b056bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature        Score\n",
      "13            ram  3520.110824\n",
      "0   battery_power    31.598158\n",
      "12       px_width    22.620882\n",
      "11      px_height    19.484842\n",
      "8       mobile_wt     3.594318\n",
      "6      int_memory     2.922996\n",
      "9         n_cores     2.625415\n",
      "14           sc_h     2.225984\n",
      "15           sc_w     1.671000\n",
      "16      talk_time     1.628811\n",
      "7           m_dep     1.500682\n",
      "18   touch_screen     1.293302\n",
      "5          four_g     1.059525\n",
      "10             pc     0.825446\n",
      "4              fc     0.772182\n",
      "2     clock_speed     0.493708\n",
      "1            blue     0.476768\n",
      "17        three_g     0.457320\n",
      "3        dual_sim     0.428239\n",
      "19           wifi     0.284940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# X fitur input dan Y data variabel\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "x_train = selector.fit_transform(X, Y)\n",
    "\n",
    "# print score setiap fitur\n",
    "scores = pd.DataFrame({'Feature': X.columns, 'Score': selector.scores_})\n",
    "scores.sort_values(by='Score', ascending=False, inplace=True)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbef3063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>7</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>53</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>41</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>44</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>39</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>36</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>46</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>45</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  int_memory  mobile_wt  n_cores  px_height  px_width  \\\n",
       "0               842           7        188        2         20       756   \n",
       "1              1021          53        136        3        905      1988   \n",
       "2               563          41        145        5       1263      1716   \n",
       "3               615          10        131        6       1216      1786   \n",
       "4              1821          44        141        2       1208      1212   \n",
       "...             ...         ...        ...      ...        ...       ...   \n",
       "1995            794           2        106        6       1222      1890   \n",
       "1996           1965          39        187        4        915      1965   \n",
       "1997           1911          36        108        8        868      1632   \n",
       "1998           1512          46        145        5        336       670   \n",
       "1999            510          45        168        6        483       754   \n",
       "\n",
       "       ram  sc_h  sc_w  talk_time  \n",
       "0     2549     9     7         19  \n",
       "1     2631    17     3          7  \n",
       "2     2603    11     2          9  \n",
       "3     2769    16     8         11  \n",
       "4     1411     8     2         15  \n",
       "...    ...   ...   ...        ...  \n",
       "1995   668    13     4         19  \n",
       "1996  2032    11    10         16  \n",
       "1997  3057     9     1          5  \n",
       "1998   869    18    10         19  \n",
       "1999  3919    19     4          2  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_num_features = X.columns[selector.get_support()]\n",
    "data1=X[selected_num_features]\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0de105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\AppData\\Local\\Temp\\ipykernel_21520\\769931367.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1['price_range']=datatrain['price_range']\n"
     ]
    }
   ],
   "source": [
    "# Memasukkan \"SalePrice\" ke data1 untuk pembuatan model\n",
    "data1['price_range']=datatrain['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "767fae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery_power     763.50\n",
      "int_memory         32.00\n",
      "mobile_wt          61.00\n",
      "n_cores             4.00\n",
      "px_height         664.50\n",
      "px_width          758.25\n",
      "ram              1857.00\n",
      "sc_h                7.00\n",
      "sc_w                7.00\n",
      "talk_time          10.00\n",
      "price_range         1.50\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Mendefinisikan IQR untuk menghilangkan data outlier\n",
    "Q1 = data1.quantile(q=.25)\n",
    "Q3 = data1.quantile(q=.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deb1388d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>7</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>53</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>905.0</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>41</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>44</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>39</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>915.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>36</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>868.0</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>46</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>336.0</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>45</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>483.0</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  int_memory  mobile_wt  n_cores  px_height  px_width  \\\n",
       "0               842           7        188        2       20.0       756   \n",
       "1              1021          53        136        3      905.0      1988   \n",
       "2               563          41        145        5     1263.0      1716   \n",
       "3               615          10        131        6     1216.0      1786   \n",
       "4              1821          44        141        2     1208.0      1212   \n",
       "...             ...         ...        ...      ...        ...       ...   \n",
       "1995            794           2        106        6     1222.0      1890   \n",
       "1996           1965          39        187        4      915.0      1965   \n",
       "1997           1911          36        108        8      868.0      1632   \n",
       "1998           1512          46        145        5      336.0       670   \n",
       "1999            510          45        168        6      483.0       754   \n",
       "\n",
       "       ram  sc_h  sc_w  talk_time  price_range  \n",
       "0     2549     9     7         19            1  \n",
       "1     2631    17     3          7            2  \n",
       "2     2603    11     2          9            2  \n",
       "3     2769    16     8         11            2  \n",
       "4     1411     8     2         15            1  \n",
       "...    ...   ...   ...        ...          ...  \n",
       "1995   668    13     4         19            0  \n",
       "1996  2032    11    10         16            2  \n",
       "1997  3057     9     1          5            3  \n",
       "1998   869    18    10         19            0  \n",
       "1999  3919    19     4          2            3  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menghilangkan data outlier\n",
    "data1 = data1[~((data1<(Q1-1.5*IQR)) | (data1>(Q3+1.5*IQR)))]\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "045a4ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power    0\n",
       "int_memory       0\n",
       "mobile_wt        0\n",
       "n_cores          0\n",
       "px_height        2\n",
       "px_width         0\n",
       "ram              0\n",
       "sc_h             0\n",
       "sc_w             0\n",
       "talk_time        0\n",
       "price_range      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melihat observasi yang NaN di setiap fitur\n",
    "data1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52ac1d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  int_memory  mobile_wt  n_cores  px_height  px_width     ram  \\\n",
       "0          842.0         7.0      188.0      2.0       20.0     756.0  2549.0   \n",
       "1         1021.0        53.0      136.0      3.0      905.0    1988.0  2631.0   \n",
       "2          563.0        41.0      145.0      5.0     1263.0    1716.0  2603.0   \n",
       "3          615.0        10.0      131.0      6.0     1216.0    1786.0  2769.0   \n",
       "4         1821.0        44.0      141.0      2.0     1208.0    1212.0  1411.0   \n",
       "\n",
       "   sc_h  sc_w  talk_time  price_range  \n",
       "0   9.0   7.0       19.0          1.0  \n",
       "1  17.0   3.0        7.0          2.0  \n",
       "2  11.0   2.0        9.0          2.0  \n",
       "3  16.0   8.0       11.0          2.0  \n",
       "4   8.0   2.0       15.0          1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import KNNImputer \n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Imputasi Outlier\n",
    "imputer = KNNImputer()\n",
    "imputasi_knn=imputer.fit_transform(data1)\n",
    "data1=pd.DataFrame(data=imputasi_knn, columns=data1.columns)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d1956c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power    0\n",
       "int_memory       0\n",
       "mobile_wt        0\n",
       "n_cores          0\n",
       "px_height        0\n",
       "px_width         0\n",
       "ram              0\n",
       "sc_h             0\n",
       "sc_w             0\n",
       "talk_time        0\n",
       "price_range      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55c8beef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek duplicate\n",
    "data1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d99820e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1238.518500</td>\n",
       "      <td>32.046500</td>\n",
       "      <td>140.249000</td>\n",
       "      <td>4.520500</td>\n",
       "      <td>643.865300</td>\n",
       "      <td>1251.515500</td>\n",
       "      <td>2124.213000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>5.767000</td>\n",
       "      <td>11.011000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>439.418206</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>441.930061</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>1.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>851.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>874.750000</td>\n",
       "      <td>1207.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2146.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1615.250000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>946.250000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>3064.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3998.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power   int_memory    mobile_wt      n_cores    px_height  \\\n",
       "count    2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean     1238.518500    32.046500   140.249000     4.520500   643.865300   \n",
       "std       439.418206    18.145715    35.399655     2.287837   441.930061   \n",
       "min       501.000000     2.000000    80.000000     1.000000     0.000000   \n",
       "25%       851.750000    16.000000   109.000000     3.000000   282.750000   \n",
       "50%      1226.000000    32.000000   141.000000     4.000000   564.000000   \n",
       "75%      1615.250000    48.000000   170.000000     7.000000   946.250000   \n",
       "max      1998.000000    64.000000   200.000000     8.000000  1920.000000   \n",
       "\n",
       "          px_width          ram         sc_h         sc_w    talk_time  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean   1251.515500  2124.213000    12.306500     5.767000    11.011000   \n",
       "std     432.199447  1084.732044     4.213245     4.356398     5.463955   \n",
       "min     500.000000   256.000000     5.000000     0.000000     2.000000   \n",
       "25%     874.750000  1207.500000     9.000000     2.000000     6.000000   \n",
       "50%    1247.000000  2146.500000    12.000000     5.000000    11.000000   \n",
       "75%    1633.000000  3064.500000    16.000000     9.000000    16.000000   \n",
       "max    1998.000000  3998.000000    19.000000    18.000000    20.000000   \n",
       "\n",
       "       price_range  \n",
       "count  2000.000000  \n",
       "mean      1.500000  \n",
       "std       1.118314  \n",
       "min       0.000000  \n",
       "25%       0.750000  \n",
       "50%       1.500000  \n",
       "75%       2.250000  \n",
       "max       3.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deskripsi data1\n",
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08cada2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melihat boxplot untuk visualisasi model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.boxplot(data=data1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc1ef032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5691bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=data1.drop('price_range',axis=1)\n",
    "y1=data1['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2aadadd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>3057.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>3919.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  int_memory  mobile_wt  n_cores  px_height  px_width  \\\n",
       "0             842.0         7.0      188.0      2.0       20.0     756.0   \n",
       "1            1021.0        53.0      136.0      3.0      905.0    1988.0   \n",
       "2             563.0        41.0      145.0      5.0     1263.0    1716.0   \n",
       "3             615.0        10.0      131.0      6.0     1216.0    1786.0   \n",
       "4            1821.0        44.0      141.0      2.0     1208.0    1212.0   \n",
       "...             ...         ...        ...      ...        ...       ...   \n",
       "1995          794.0         2.0      106.0      6.0     1222.0    1890.0   \n",
       "1996         1965.0        39.0      187.0      4.0      915.0    1965.0   \n",
       "1997         1911.0        36.0      108.0      8.0      868.0    1632.0   \n",
       "1998         1512.0        46.0      145.0      5.0      336.0     670.0   \n",
       "1999          510.0        45.0      168.0      6.0      483.0     754.0   \n",
       "\n",
       "         ram  sc_h  sc_w  talk_time  \n",
       "0     2549.0   9.0   7.0       19.0  \n",
       "1     2631.0  17.0   3.0        7.0  \n",
       "2     2603.0  11.0   2.0        9.0  \n",
       "3     2769.0  16.0   8.0       11.0  \n",
       "4     1411.0   8.0   2.0       15.0  \n",
       "...      ...   ...   ...        ...  \n",
       "1995   668.0  13.0   4.0       19.0  \n",
       "1996  2032.0  11.0  10.0       16.0  \n",
       "1997  3057.0   9.0   1.0        5.0  \n",
       "1998   869.0  18.0  10.0       19.0  \n",
       "1999  3919.0  19.0   4.0        2.0  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a9e62b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       2.0\n",
       "2       2.0\n",
       "3       2.0\n",
       "4       1.0\n",
       "       ... \n",
       "1995    0.0\n",
       "1996    2.0\n",
       "1997    3.0\n",
       "1998    0.0\n",
       "1999    3.0\n",
       "Name: price_range, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9a565c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x1.values, y1.values, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65db7718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1745.,    3.,  105., ...,    5.,    0.,    2.],\n",
       "       [ 535.,   54.,  145., ...,   14.,    8.,   10.],\n",
       "       [1577.,   42.,  197., ...,   19.,    6.,   12.],\n",
       "       ...,\n",
       "       [1829.,   15.,  160., ...,   16.,   11.,   12.],\n",
       "       [1927.,   11.,  190., ...,   16.,   11.,   18.],\n",
       "       [ 635.,   50.,   97., ...,   13.,   12.,   12.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8af5cb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.646e+03, 2.500e+01, 2.000e+02, ..., 8.000e+00, 6.000e+00,\n",
       "        1.100e+01],\n",
       "       [1.182e+03, 8.000e+00, 1.380e+02, ..., 1.900e+01, 1.700e+01,\n",
       "        1.900e+01],\n",
       "       [1.972e+03, 1.400e+01, 1.960e+02, ..., 8.000e+00, 1.000e+00,\n",
       "        8.000e+00],\n",
       "       ...,\n",
       "       [1.068e+03, 5.200e+01, 9.700e+01, ..., 1.600e+01, 1.000e+00,\n",
       "        1.500e+01],\n",
       "       [9.860e+02, 2.300e+01, 1.830e+02, ..., 1.600e+01, 9.000e+00,\n",
       "        1.900e+01],\n",
       "       [1.712e+03, 2.300e+01, 1.550e+02, ..., 5.000e+00, 0.000e+00,\n",
       "        1.500e+01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c20a5ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., ..., 2., 3., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c17f8bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Habil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.05, 0.1, 0.7, 0.5, 1, 5, 10, 50, 100],\n",
       "                         'kernel': ['poly', 'rbf']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C':[0.01,0.05,0.1,0.7,0.5,1,5,10,50,100],     # hyperparameter yang akan dievaluasi untuk SVC\n",
    "             'kernel':['poly','rbf']}\n",
    "\n",
    "grid_search = GridSearchCV(svc, params, cv=kfold, scoring='f1')\n",
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8389d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.01, 'kernel': 'poly'}, nan)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_, grid_search.cv_results_['mean_test_score'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ab3e535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, kernel='poly')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d66ed92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., 3., 1., 1., 2., 0., 3., 1., 0., 0., 2., 3., 2., 2., 3.,\n",
       "       3., 1., 0., 0., 1., 0., 2., 0., 1., 3., 2., 2., 0., 0., 0., 3., 0.,\n",
       "       1., 1., 2., 0., 3., 0., 2., 3., 2., 0., 2., 2., 2., 0., 3., 1., 3.,\n",
       "       1., 0., 0., 0., 0., 1., 3., 0., 0., 0., 3., 3., 1., 0., 0., 3., 3.,\n",
       "       1., 2., 2., 2., 0., 1., 2., 0., 0., 3., 2., 2., 3., 2., 1., 0., 1.,\n",
       "       3., 1., 3., 3., 0., 3., 3., 2., 1., 3., 2., 2., 3., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 3., 2., 0., 1., 1., 0., 0., 3., 1., 2., 2., 3., 2., 0.,\n",
       "       2., 0., 3., 2., 1., 3., 3., 0., 2., 0., 2., 3., 0., 2., 2., 0., 3.,\n",
       "       1., 0., 0., 2., 2., 0., 2., 2., 0., 0., 0., 1., 1., 2., 3., 1., 1.,\n",
       "       0., 2., 2., 0., 1., 0., 2., 2., 3., 2., 2., 1., 0., 0., 2., 2., 3.,\n",
       "       3., 0., 0., 0., 3., 1., 1., 2., 0., 0., 0., 0., 0., 0., 3., 2., 0.,\n",
       "       3., 0., 0., 0., 0., 1., 3., 3., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4a8d74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138719210125484"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82da6b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------Machine Learning - Classification------------------------\n",
      "\n",
      "\n",
      "Classification Report for Data Test\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91        59\n",
      "         1.0       0.97      0.78      0.86        49\n",
      "         2.0       0.90      0.98      0.94        45\n",
      "         3.0       1.00      0.89      0.94        47\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.93      0.91      0.91       200\n",
      "weighted avg       0.92      0.92      0.91       200\n",
      "\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "def evaluation_parametrics(name,y_val, y_pred):\n",
    "    \n",
    "    print(\"\\n------------------------{}------------------------\\n\".format(name))\n",
    "\n",
    "    cm_test = confusion_matrix(y_val, y_pred)\n",
    "    t1 = ConfusionMatrixDisplay(cm_test)    \n",
    "    print(\"\\nClassification Report for Data Test\\n\")\n",
    "    print(classification_report(y_val, y_pred))   \n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    t1.plot()\n",
    "    \n",
    "evaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8efdebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [2. 1.]\n",
      " [1. 0.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [3. 2.]\n",
      " [2. 2.]\n",
      " [1. 0.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [3. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [1. 0.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [1. 0.]\n",
      " [3. 2.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 2.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [2. 2.]\n",
      " [0. 0.]\n",
      " [3. 3.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((y_test.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ced972aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(model, x_test, y_test, n_repeats=10,\n",
    "                                scoring='f1_weighted', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "126b01ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ram</th>\n",
       "      <th>battery_power</th>\n",
       "      <th>px_width</th>\n",
       "      <th>px_height</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1646.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1182.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>989.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>3892.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>615.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1986.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1510.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1068.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>986.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1712.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ram  battery_power  px_width  px_height  mobile_wt  int_memory  \\\n",
       "0    1646.0           25.0     200.0        2.0      211.0      1608.0   \n",
       "1    1182.0            8.0     138.0        8.0      275.0       986.0   \n",
       "2    1972.0           14.0     196.0        7.0      293.0       952.0   \n",
       "3     989.0           17.0     166.0        3.0      256.0      1394.0   \n",
       "4     615.0           58.0     130.0        5.0     1021.0      1958.0   \n",
       "..      ...            ...       ...        ...        ...         ...   \n",
       "195  1986.0           51.0     165.0        8.0      282.0      1358.0   \n",
       "196  1510.0           47.0     138.0        2.0      118.0      1170.0   \n",
       "197  1068.0           52.0      97.0        8.0      994.0      1500.0   \n",
       "198   986.0           23.0     183.0        8.0      471.0       800.0   \n",
       "199  1712.0           23.0     155.0        7.0      155.0       663.0   \n",
       "\n",
       "     n_cores  sc_h  sc_w  talk_time  \n",
       "0      686.0   8.0   6.0       11.0  \n",
       "1     2563.0  19.0  17.0       19.0  \n",
       "2     1316.0   8.0   1.0        8.0  \n",
       "3     3892.0  18.0   7.0       19.0  \n",
       "4     1906.0  14.0   5.0        5.0  \n",
       "..       ...   ...   ...        ...  \n",
       "195   1614.0  17.0  12.0        3.0  \n",
       "196    887.0  18.0   6.0        5.0  \n",
       "197   1436.0  16.0   1.0       15.0  \n",
       "198   2385.0  16.0   9.0       19.0  \n",
       "199   1422.0   5.0   0.0       15.0  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['ram', 'battery_power', 'px_width', 'px_height', 'mobile_wt', 'int_memory', 'n_cores', 'sc_h', 'sc_w', 'talk_time']\n",
    "x_test = pd.DataFrame(data=x_test,columns=col)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9282661c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_sorted = []\n",
    "columns_sorted = []\n",
    "\n",
    "for res, col in sorted(zip(result.importances_mean, x_test.columns.values), reverse=True):\n",
    "  result_sorted.append(res)\n",
    "  columns_sorted.append(col)\n",
    "\n",
    "sns.barplot(x = result_sorted, y = columns_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04b26b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_klasifikasi_price.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'model_klasifikasi_price.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
